{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (Linear Kernel): 0.48\n",
      "Confusion Matrix (Validation, Linear Kernel):\n",
      " [[46 50]\n",
      " [54 50]]\n",
      "Classification Report (Validation, Linear Kernel):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47        96\n",
      "           1       0.50      0.48      0.49       104\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.48      0.48      0.48       200\n",
      "weighted avg       0.48      0.48      0.48       200\n",
      "\n",
      "Test Accuracy (Linear Kernel): 0.526\n",
      "Confusion Matrix (Test, Linear Kernel):\n",
      " [[123 127]\n",
      " [110 140]]\n",
      "Classification Report (Test, Linear Kernel):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.49      0.51       250\n",
      "           1       0.52      0.56      0.54       250\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.53      0.53      0.53       500\n",
      "weighted avg       0.53      0.53      0.53       500\n",
      "\n",
      "-------------------------------------------------------\n",
      "Validation Accuracy (Poly Kernel): 0.57\n",
      "Confusion Matrix (Validation, Poly Kernel):\n",
      " [[84 12]\n",
      " [74 30]]\n",
      "Classification Report (Validation, Poly Kernel):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66        96\n",
      "           1       0.71      0.29      0.41       104\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.62      0.58      0.54       200\n",
      "weighted avg       0.63      0.57      0.53       200\n",
      "\n",
      "Test Accuracy (Poly Kernel): 0.566\n",
      "Confusion Matrix (Test, Poly Kernel):\n",
      " [[216  34]\n",
      " [183  67]]\n",
      "Classification Report (Test, Poly Kernel):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.86      0.67       250\n",
      "           1       0.66      0.27      0.38       250\n",
      "\n",
      "    accuracy                           0.57       500\n",
      "   macro avg       0.60      0.57      0.52       500\n",
      "weighted avg       0.60      0.57      0.52       500\n",
      "\n",
      "-------------------------------------------------------\n",
      "Validation Accuracy (Rbf Kernel): 0.585\n",
      "Confusion Matrix (Validation, Rbf Kernel):\n",
      " [[60 36]\n",
      " [47 57]]\n",
      "Classification Report (Validation, Rbf Kernel):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59        96\n",
      "           1       0.61      0.55      0.58       104\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.59      0.59      0.58       200\n",
      "weighted avg       0.59      0.58      0.58       200\n",
      "\n",
      "Test Accuracy (Rbf Kernel): 0.588\n",
      "Confusion Matrix (Test, Rbf Kernel):\n",
      " [[155  95]\n",
      " [111 139]]\n",
      "Classification Report (Test, Rbf Kernel):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60       250\n",
      "           1       0.59      0.56      0.57       250\n",
      "\n",
      "    accuracy                           0.59       500\n",
      "   macro avg       0.59      0.59      0.59       500\n",
      "weighted avg       0.59      0.59      0.59       500\n",
      "\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_images_from_directory2(directory, num_images):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  \n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (64, 64))  \n",
    "            images.append(img.flatten())  \n",
    "            labels.append(1 if \"cat\" in filename else 0)  \n",
    "            count += 1\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_directory(directory, num_images):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "         \n",
    "            img = cv2.imread(os.path.join(directory, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (64, 64))  \n",
    "            images.append(img.flatten())  \n",
    "            labels.append(1 if \"cat\" in filename else 0)  \n",
    "            count += 1\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "train_dog_images, train_dog_labels = load_images_from_directory(\"train/dog\", num_images=500)\n",
    "train_cat_images, train_cat_labels = load_images_from_directory(\"train/cat\", num_images=500)\n",
    "\n",
    "X_train = np.vstack((train_dog_images, train_cat_images))\n",
    "y_train = np.concatenate((train_dog_labels, train_cat_labels))\n",
    "\n",
    "test_dog_images, test_dog_labels = load_images_from_directory(\"test/dog\", num_images=250)\n",
    "test_cat_images, test_cat_labels = load_images_from_directory(\"test/cat\", num_images=250)\n",
    "\n",
    "X_test = np.vstack((test_dog_images, test_cat_images))\n",
    "y_test = np.concatenate((test_dog_labels, test_cat_labels))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "for kernel in kernels:\n",
    "    svm_classifier = SVC(kernel=kernel, C=1.0)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    y_val_pred = svm_classifier.predict(X_val)\n",
    "\n",
    "    accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "    conf_matrix_val = confusion_matrix(y_val, y_val_pred)\n",
    "    classification_rep_val = classification_report(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"Validation Accuracy ({kernel.capitalize()} Kernel): {accuracy_val}\")\n",
    "    print(f\"Confusion Matrix (Validation, {kernel.capitalize()} Kernel):\\n\", conf_matrix_val)\n",
    "    print(f\"Classification Report (Validation, {kernel.capitalize()} Kernel):\\n\", classification_rep_val)\n",
    "\n",
    "    y_test_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate accuracy on the test set\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    classification_rep_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Test Accuracy ({kernel.capitalize()} Kernel): {accuracy_test}\")\n",
    "    print(f\"Confusion Matrix (Test, {kernel.capitalize()} Kernel):\\n\", conf_matrix_test)\n",
    "    print(f\"Classification Report (Test, {kernel.capitalize()} Kernel):\\n\", classification_rep_test)\n",
    "    print(\"-------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert image to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_images_from_directory(directory, num_images, label):\n",
    "    data = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "            img = cv2.resize(img, (64, 64))  \n",
    "            flattened_img = img.flatten()  \n",
    "            data.append(list(flattened_img) + [label])  \n",
    "            count += 1\n",
    "    return data\n",
    "\n",
    "train_dog_data = load_images_from_directory(\"train/dog\", num_images=1000, label='dog')\n",
    "train_cat_data = load_images_from_directory(\"train/cat\", num_images=1000, label='cat')\n",
    "\n",
    "train_data = train_dog_data + train_cat_data\n",
    "\n",
    "columns = [f\"pixel_{i}\" for i in range(64 * 64)] + ['label']\n",
    "df_train = pd.DataFrame(train_data, columns=columns)\n",
    "\n",
    "df_train.to_csv('train_data.csv', index=False)\n",
    "\n",
    "test_dog_data = load_images_from_directory(\"test/dog\", num_images=1000, label='dog')\n",
    "test_cat_data = load_images_from_directory(\"test/cat\", num_images=1000, label='cat')\n",
    "\n",
    "test_data = test_dog_data + test_cat_data\n",
    "\n",
    "df_test = pd.DataFrame(test_data, columns=columns)\n",
    "\n",
    "# Save the test data to a CSV file\n",
    "df_test.to_csv('test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5175\n",
      "Confusion Matrix (Test):\n",
      " [[570 430]\n",
      " [535 465]]\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.52      0.57      0.54      1000\n",
      "         dog       0.52      0.47      0.49      1000\n",
      "\n",
      "    accuracy                           0.52      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.52      0.52      0.52      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "\n",
    "X_train = df_train.drop('label', axis=1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "X_test = df_test.drop('label', axis=1)\n",
    "y_test = df_test['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=0.1)\n",
    "models = cross_validate(svm_classifier, X_train, y_train.ravel(), cv=5,  return_estimator=True,  n_jobs=5)\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "classification_rep_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "print(\"Confusion Matrix (Test):\\n\", conf_matrix_test)\n",
    "print(\"Classification Report (Test):\\n\", classification_rep_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5117784105617396\n",
      "Confusion Matrix (Test):\n",
      " [[1665  254]\n",
      " [1632  312]]\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.64      1919\n",
      "           1       0.55      0.16      0.25      1944\n",
      "\n",
      "    accuracy                           0.51      3863\n",
      "   macro avg       0.53      0.51      0.44      3863\n",
      "weighted avg       0.53      0.51      0.44      3863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_images_from_directory2(directory, num_images):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "            img = cv2.resize(img, (64, 64))  \n",
    "            images.append(img.flatten())  \n",
    "            labels.append(1 if \"cat\" in filename else 0)  \n",
    "            count += 1\n",
    "    return np.array(images), np.array(labels)\n",
    "def load_images_from_directory(directory, num_images):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (64, 64))  \n",
    "            images.append(img.flatten())  \n",
    "            labels.append(1 if \"cat\" in filename else 0)  \n",
    "            count += 1\n",
    "    return np.array(images), np.array(labels)\n",
    "train_dog_images, train_dog_labels = load_images_from_directory(\"train/dog\", num_images=500)\n",
    "train_cat_images, train_cat_labels = load_images_from_directory(\"train/cat\", num_images=500)\n",
    "\n",
    "X_train = np.vstack((train_dog_images, train_cat_images))\n",
    "y_train = np.concatenate((train_dog_labels, train_cat_labels))\n",
    "\n",
    "test_dog_images, test_dog_labels = load_images_from_directory(\"test/dog\", num_images=3000)\n",
    "test_cat_images, test_cat_labels = load_images_from_directory(\"test/cat\", num_images=3000)\n",
    "\n",
    "X_test = np.vstack((test_dog_images, test_cat_images))\n",
    "y_test = np.concatenate((test_dog_labels, test_cat_labels))\n",
    "\n",
    "# Standardize pixel values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='poly', C=0.1)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "classification_rep_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "print(\"Confusion Matrix (Test):\\n\", conf_matrix_test)\n",
    "print(\"Classification Report (Test):\\n\", classification_rep_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
